{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FkhnkOP-BN6e",
        "outputId": "237e5dd2-45bf-4cca-9ebb-81e616008473"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting tf-agents[reverb]\n",
            "  Downloading tf_agents-0.15.0-py3-none-any.whl (1.4 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.4/1.4 MB\u001b[0m \u001b[31m15.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: pillow in /usr/local/lib/python3.8/dist-packages (from tf-agents[reverb]) (7.1.2)\n",
            "Collecting gym<=0.23.0,>=0.17.0\n",
            "  Downloading gym-0.23.0.tar.gz (624 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m624.4/624.4 KB\u001b[0m \u001b[31m24.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: six>=1.10.0 in /usr/local/lib/python3.8/dist-packages (from tf-agents[reverb]) (1.15.0)\n",
            "Requirement already satisfied: gin-config>=0.4.0 in /usr/local/lib/python3.8/dist-packages (from tf-agents[reverb]) (0.5.0)\n",
            "Requirement already satisfied: cloudpickle>=1.3 in /usr/local/lib/python3.8/dist-packages (from tf-agents[reverb]) (2.2.1)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.8/dist-packages (from tf-agents[reverb]) (4.4.0)\n",
            "Collecting pygame==2.1.0\n",
            "  Downloading pygame-2.1.0-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (18.3 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m18.3/18.3 MB\u001b[0m \u001b[31m35.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: absl-py>=0.6.1 in /usr/local/lib/python3.8/dist-packages (from tf-agents[reverb]) (1.4.0)\n",
            "Requirement already satisfied: tensorflow-probability>=0.18.0 in /usr/local/lib/python3.8/dist-packages (from tf-agents[reverb]) (0.19.0)\n",
            "Requirement already satisfied: wrapt>=1.11.1 in /usr/local/lib/python3.8/dist-packages (from tf-agents[reverb]) (1.14.1)\n",
            "Requirement already satisfied: protobuf>=3.11.3 in /usr/local/lib/python3.8/dist-packages (from tf-agents[reverb]) (3.19.6)\n",
            "Requirement already satisfied: numpy>=1.13.3 in /usr/local/lib/python3.8/dist-packages (from tf-agents[reverb]) (1.21.6)\n",
            "Collecting dm-reverb~=0.10.0\n",
            "  Downloading dm_reverb-0.10.0-cp38-cp38-manylinux2014_x86_64.whl (6.3 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.3/6.3 MB\u001b[0m \u001b[31m29.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting rlds\n",
            "  Downloading rlds-0.1.7-py3-none-manylinux2010_x86_64.whl (48 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m48.4/48.4 KB\u001b[0m \u001b[31m4.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: tensorflow==2.11.0 in /usr/local/lib/python3.8/dist-packages (from tf-agents[reverb]) (2.11.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.8/dist-packages (from tensorflow==2.11.0->tf-agents[reverb]) (23.0)\n",
            "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /usr/local/lib/python3.8/dist-packages (from tensorflow==2.11.0->tf-agents[reverb]) (1.51.1)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.8/dist-packages (from tensorflow==2.11.0->tf-agents[reverb]) (57.4.0)\n",
            "Requirement already satisfied: tensorflow-estimator<2.12,>=2.11.0 in /usr/local/lib/python3.8/dist-packages (from tensorflow==2.11.0->tf-agents[reverb]) (2.11.0)\n",
            "Requirement already satisfied: keras<2.12,>=2.11.0 in /usr/local/lib/python3.8/dist-packages (from tensorflow==2.11.0->tf-agents[reverb]) (2.11.0)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.8/dist-packages (from tensorflow==2.11.0->tf-agents[reverb]) (2.2.0)\n",
            "Requirement already satisfied: gast<=0.4.0,>=0.2.1 in /usr/local/lib/python3.8/dist-packages (from tensorflow==2.11.0->tf-agents[reverb]) (0.4.0)\n",
            "Requirement already satisfied: flatbuffers>=2.0 in /usr/local/lib/python3.8/dist-packages (from tensorflow==2.11.0->tf-agents[reverb]) (23.1.21)\n",
            "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /usr/local/lib/python3.8/dist-packages (from tensorflow==2.11.0->tf-agents[reverb]) (0.30.0)\n",
            "Requirement already satisfied: tensorboard<2.12,>=2.11 in /usr/local/lib/python3.8/dist-packages (from tensorflow==2.11.0->tf-agents[reverb]) (2.11.2)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.8/dist-packages (from tensorflow==2.11.0->tf-agents[reverb]) (3.3.0)\n",
            "Requirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.8/dist-packages (from tensorflow==2.11.0->tf-agents[reverb]) (0.2.0)\n",
            "Requirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.8/dist-packages (from tensorflow==2.11.0->tf-agents[reverb]) (1.6.3)\n",
            "Requirement already satisfied: libclang>=13.0.0 in /usr/local/lib/python3.8/dist-packages (from tensorflow==2.11.0->tf-agents[reverb]) (15.0.6.1)\n",
            "Requirement already satisfied: h5py>=2.9.0 in /usr/local/lib/python3.8/dist-packages (from tensorflow==2.11.0->tf-agents[reverb]) (3.1.0)\n",
            "Requirement already satisfied: portpicker in /usr/local/lib/python3.8/dist-packages (from dm-reverb~=0.10.0->tf-agents[reverb]) (1.3.9)\n",
            "Requirement already satisfied: dm-tree in /usr/local/lib/python3.8/dist-packages (from dm-reverb~=0.10.0->tf-agents[reverb]) (0.1.8)\n",
            "Requirement already satisfied: importlib-metadata>=4.10.0 in /usr/local/lib/python3.8/dist-packages (from gym<=0.23.0,>=0.17.0->tf-agents[reverb]) (6.0.0)\n",
            "Requirement already satisfied: gym-notices>=0.0.4 in /usr/local/lib/python3.8/dist-packages (from gym<=0.23.0,>=0.17.0->tf-agents[reverb]) (0.0.8)\n",
            "Requirement already satisfied: decorator in /usr/local/lib/python3.8/dist-packages (from tensorflow-probability>=0.18.0->tf-agents[reverb]) (4.4.2)\n",
            "Requirement already satisfied: wheel<1.0,>=0.23.0 in /usr/local/lib/python3.8/dist-packages (from astunparse>=1.6.0->tensorflow==2.11.0->tf-agents[reverb]) (0.38.4)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.8/dist-packages (from importlib-metadata>=4.10.0->gym<=0.23.0,>=0.17.0->tf-agents[reverb]) (3.12.1)\n",
            "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /usr/local/lib/python3.8/dist-packages (from tensorboard<2.12,>=2.11->tensorflow==2.11.0->tf-agents[reverb]) (1.8.1)\n",
            "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /usr/local/lib/python3.8/dist-packages (from tensorboard<2.12,>=2.11->tensorflow==2.11.0->tf-agents[reverb]) (0.4.6)\n",
            "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.8/dist-packages (from tensorboard<2.12,>=2.11->tensorflow==2.11.0->tf-agents[reverb]) (2.25.1)\n",
            "Requirement already satisfied: tensorboard-data-server<0.7.0,>=0.6.0 in /usr/local/lib/python3.8/dist-packages (from tensorboard<2.12,>=2.11->tensorflow==2.11.0->tf-agents[reverb]) (0.6.1)\n",
            "Requirement already satisfied: google-auth<3,>=1.6.3 in /usr/local/lib/python3.8/dist-packages (from tensorboard<2.12,>=2.11->tensorflow==2.11.0->tf-agents[reverb]) (2.16.0)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.8/dist-packages (from tensorboard<2.12,>=2.11->tensorflow==2.11.0->tf-agents[reverb]) (3.4.1)\n",
            "Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.8/dist-packages (from tensorboard<2.12,>=2.11->tensorflow==2.11.0->tf-agents[reverb]) (1.0.1)\n",
            "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.8/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.12,>=2.11->tensorflow==2.11.0->tf-agents[reverb]) (5.3.0)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.8/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.12,>=2.11->tensorflow==2.11.0->tf-agents[reverb]) (4.9)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.8/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.12,>=2.11->tensorflow==2.11.0->tf-agents[reverb]) (0.2.8)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.8/dist-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.12,>=2.11->tensorflow==2.11.0->tf-agents[reverb]) (1.3.1)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.8/dist-packages (from requests<3,>=2.21.0->tensorboard<2.12,>=2.11->tensorflow==2.11.0->tf-agents[reverb]) (2.10)\n",
            "Requirement already satisfied: chardet<5,>=3.0.2 in /usr/local/lib/python3.8/dist-packages (from requests<3,>=2.21.0->tensorboard<2.12,>=2.11->tensorflow==2.11.0->tf-agents[reverb]) (4.0.0)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.8/dist-packages (from requests<3,>=2.21.0->tensorboard<2.12,>=2.11->tensorflow==2.11.0->tf-agents[reverb]) (1.24.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.8/dist-packages (from requests<3,>=2.21.0->tensorboard<2.12,>=2.11->tensorflow==2.11.0->tf-agents[reverb]) (2022.12.7)\n",
            "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /usr/local/lib/python3.8/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard<2.12,>=2.11->tensorflow==2.11.0->tf-agents[reverb]) (0.4.8)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.8/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.12,>=2.11->tensorflow==2.11.0->tf-agents[reverb]) (3.2.2)\n",
            "Building wheels for collected packages: gym\n",
            "  Building wheel for gym (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for gym: filename=gym-0.23.0-py3-none-any.whl size=697661 sha256=91da52689170e44e80b11db5a1023753454af7c741d82359a551ea10d848ab44\n",
            "  Stored in directory: /root/.cache/pip/wheels/e7/2f/ab/68bf956c5dde73c1856d981e54292cf58385fb60bca10b7acd\n",
            "Successfully built gym\n",
            "Installing collected packages: rlds, pygame, dm-reverb, gym, tf-agents\n",
            "  Attempting uninstall: gym\n",
            "    Found existing installation: gym 0.25.2\n",
            "    Uninstalling gym-0.25.2:\n",
            "      Successfully uninstalled gym-0.25.2\n",
            "Successfully installed dm-reverb-0.10.0 gym-0.23.0 pygame-2.1.0 rlds-0.1.7 tf-agents-0.15.0\n"
          ]
        }
      ],
      "source": [
        "!pip install tf-agents[reverb]"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from __future__ import absolute_import\n",
        "from __future__ import division\n",
        "from __future__ import print_function\n",
        "\n",
        "import abc\n",
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "\n",
        "from tf_agents.environments import py_environment\n",
        "from tf_agents.environments import tf_environment\n",
        "from tf_agents.environments import tf_py_environment\n",
        "from tf_agents.environments import utils\n",
        "from tf_agents.specs import array_spec\n",
        "from tf_agents.environments import wrappers\n",
        "from tf_agents.environments import suite_gym\n",
        "from tf_agents.trajectories import time_step as ts\n",
        "import time"
      ],
      "metadata": {
        "id": "z0HlQR7HBW3R"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "env = suite_gym.load('CartPole-v0')\n",
        "tf_env = tf_py_environment.TFPyEnvironment(env)\n",
        "\n",
        "time_step = tf_env.reset()\n",
        "rewards = []\n",
        "steps = []\n",
        "num_episodes = 5\n",
        "\n",
        "for _ in range(num_episodes):\n",
        "  episode_reward = 0\n",
        "  episode_steps = 0\n",
        "  while not time_step.is_last():\n",
        "    action = tf.random.uniform([1], 0, 2, dtype=tf.int32)\n",
        "    time_step = tf_env.step(action)\n",
        "    episode_steps += 1\n",
        "    episode_reward += time_step.reward.numpy()\n",
        "  rewards.append(episode_reward)\n",
        "  steps.append(episode_steps)\n",
        "  time_step = tf_env.reset()\n",
        "\n",
        "num_steps = np.sum(steps)\n",
        "avg_length = np.mean(steps)\n",
        "avg_reward = np.mean(rewards)\n",
        "\n",
        "print('num_episodes:', num_episodes, 'num_steps:', num_steps)\n",
        "print('avg_length', avg_length, 'avg_reward:', avg_reward)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lZNpLEDVEV85",
        "outputId": "28fe0d2a-1234-4b20-b6dc-3e4e3ff0e1f3"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "num_episodes: 5 num_steps: 98\n",
            "avg_length 19.6 avg_reward: 19.6\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "env = suite_gym.load('CartPole-v0')\n",
        "tf_env = tf_py_environment.TFPyEnvironment(env)\n",
        "\n",
        "time_step = tf_env.reset()\n",
        "rewards = []\n",
        "steps = []\n",
        "num_episodes = 15\n",
        "\n",
        "for _ in range(num_episodes):\n",
        "  episode_reward = 0\n",
        "  episode_steps = 0\n",
        "  while not time_step.is_last():\n",
        "    action = tf.random.uniform([1], 0, 2, dtype=tf.int32)\n",
        "    time_step = tf_env.step(action)\n",
        "    episode_steps += 1\n",
        "    episode_reward += time_step.reward.numpy()\n",
        "  rewards.append(episode_reward)\n",
        "  steps.append(episode_steps)\n",
        "  time_step = tf_env.reset()\n",
        "\n",
        "num_steps = np.sum(steps)\n",
        "avg_length = np.mean(steps)\n",
        "avg_reward = np.mean(rewards)\n",
        "\n",
        "print('num_episodes:', num_episodes, 'num_steps:', num_steps)\n",
        "print('avg_length', avg_length, 'avg_reward:', avg_reward)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yoLsaGsELXhv",
        "outputId": "e8d3d986-45c9-44d7-91c5-bc223ab3831f"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "num_episodes: 15 num_steps: 364\n",
            "avg_length 24.266666666666666 avg_reward: 24.266666\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "As the number of episodes and number of steps increase, the average reward increases."
      ],
      "metadata": {
        "id": "aaii7xF_fJNF"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Number of Episodes Constant"
      ],
      "metadata": {
        "id": "IUI4jzPWmHl4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "env = suite_gym.load('CartPole-v0')\n",
        "tf_env = tf_py_environment.TFPyEnvironment(env)\n",
        "\n",
        "time_step = tf_env.reset()\n",
        "rewards = []\n",
        "steps = []\n",
        "num_episodes = 15\n",
        "num_step = 45\n",
        "\n",
        "for _ in range(num_episodes):\n",
        "  episode_reward = 0\n",
        "  episode_steps = 0\n",
        "  for _ in range(num_step):\n",
        "    action = tf.random.uniform([1], 0, 2, dtype=tf.int32)\n",
        "    time_step = tf_env.step(action)\n",
        "    episode_steps += 1\n",
        "    episode_reward += time_step.reward.numpy()\n",
        "  rewards.append(episode_reward)\n",
        "  steps.append(episode_steps)\n",
        "  time_step = tf_env.reset()\n",
        "\n",
        "num_steps = num_step\n",
        "avg_length = np.mean(steps)\n",
        "avg_reward = np.mean(rewards)\n",
        "\n",
        "print('num_episodes:', num_episodes, 'num_steps:', num_steps)\n",
        "print('avg_reward:', avg_reward)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8zUI5UNnfh0e",
        "outputId": "9064ce53-8ef4-4bdf-db80-6bd69a1a4af7"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "num_episodes: 15 num_steps: 45\n",
            "avg_reward: 43.466667\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "env = suite_gym.load('CartPole-v0')\n",
        "tf_env = tf_py_environment.TFPyEnvironment(env)\n",
        "\n",
        "time_step = tf_env.reset()\n",
        "rewards = []\n",
        "steps = []\n",
        "num_episodes = 15\n",
        "num_step = 35\n",
        "\n",
        "for _ in range(num_episodes):\n",
        "  episode_reward = 0\n",
        "  episode_steps = 0\n",
        "  for _ in range(num_step):\n",
        "    action = tf.random.uniform([1], 0, 2, dtype=tf.int32)\n",
        "    time_step = tf_env.step(action)\n",
        "    episode_steps += 1\n",
        "    episode_reward += time_step.reward.numpy()\n",
        "  rewards.append(episode_reward)\n",
        "  steps.append(episode_steps)\n",
        "  time_step = tf_env.reset()\n",
        "\n",
        "num_steps = num_step\n",
        "avg_length = np.mean(steps)\n",
        "avg_reward = np.mean(rewards)\n",
        "\n",
        "print('num_episodes:', num_episodes, 'num_steps:', num_steps)\n",
        "print('avg_reward:', avg_reward)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vtFBPiyLgEwi",
        "outputId": "e56a8e92-baed-4767-ae52-d88cc0eac5b6"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "num_episodes: 15 num_steps: 35\n",
            "avg_reward: 33.8\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "While keeping the number of episodes constant, we observe that an increase in steps gives an increase in the average reward."
      ],
      "metadata": {
        "id": "bYUWYx77lTUE"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Number of Steps Constant"
      ],
      "metadata": {
        "id": "V-JYzvo_mAvn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "env = suite_gym.load('CartPole-v0')\n",
        "tf_env = tf_py_environment.TFPyEnvironment(env)\n",
        "\n",
        "time_step = tf_env.reset()\n",
        "rewards = []\n",
        "steps = []\n",
        "num_episodes = 5\n",
        "num_step = 50\n",
        "\n",
        "for _ in range(num_episodes):\n",
        "  episode_reward = 0\n",
        "  episode_steps = 0\n",
        "  for _ in range(num_step):\n",
        "    action = tf.random.uniform([1], 0, 2, dtype=tf.int32)\n",
        "    time_step = tf_env.step(action)\n",
        "    episode_steps += 1\n",
        "    episode_reward += time_step.reward.numpy()\n",
        "  rewards.append(episode_reward)\n",
        "  steps.append(episode_steps)\n",
        "  time_step = tf_env.reset()\n",
        "\n",
        "num_steps = num_step\n",
        "avg_length = np.mean(steps)\n",
        "avg_reward = np.mean(rewards)\n",
        "\n",
        "print('num_episodes:', num_episodes, 'num_steps:', num_steps)\n",
        "print('avg_length', avg_length, 'avg_reward:', avg_reward)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FCQ2lY6tlSm8",
        "outputId": "af82a8ae-4f8b-4cec-b7bb-eb2fcd25b528"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "num_episodes: 5 num_steps: 50\n",
            "avg_length 50.0 avg_reward: 48.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "env = suite_gym.load('CartPole-v0')\n",
        "tf_env = tf_py_environment.TFPyEnvironment(env)\n",
        "\n",
        "time_step = tf_env.reset()\n",
        "rewards = []\n",
        "steps = []\n",
        "num_episodes = 95\n",
        "num_step = 50\n",
        "\n",
        "for _ in range(num_episodes):\n",
        "  episode_reward = 0\n",
        "  episode_steps = 0\n",
        "  for _ in range(num_step):\n",
        "    action = tf.random.uniform([1], 0, 2, dtype=tf.int32)\n",
        "    time_step = tf_env.step(action)\n",
        "    episode_steps += 1\n",
        "    episode_reward += time_step.reward.numpy()\n",
        "  rewards.append(episode_reward)\n",
        "  steps.append(episode_steps)\n",
        "  time_step = tf_env.reset()\n",
        "\n",
        "num_steps = num_step\n",
        "avg_length = np.mean(steps)\n",
        "avg_reward = np.mean(rewards)\n",
        "\n",
        "print('num_episodes:', num_episodes, 'num_steps:', num_steps)\n",
        "print('avg_length', avg_length, 'avg_reward:', avg_reward)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-Eke0ggOgHRB",
        "outputId": "9f86d4c5-4e74-4979-e235-a28d746fde46"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "num_episodes: 125 num_steps: 50\n",
            "avg_length 50.0 avg_reward: 48.208\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "When increasing number of episodes while keeping the steps constant, we see a silght increase in the rewards"
      ],
      "metadata": {
        "id": "WqiQrzful4P0"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Comparison"
      ],
      "metadata": {
        "id": "nfLxaxPOmQ2Q"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The method of keeping episodes constant and increasing number of steps has a better result in terms of growth in value of average result."
      ],
      "metadata": {
        "id": "VwdwD4RBmWX_"
      }
    }
  ]
}